# detection.py - Detecci√≥n de objetos y √°reas
import json
import threading
from typing import List, Dict, Optional, Tuple
from .utils import _cv2_safe, _np_safe, _get_frame_dimensions, create_polygon_mask

# Variables para detecci√≥n de objetos
_background_subtractor = None
_is_learning_background = False
_background_model_saved = False  # Indica si hay un modelo de fondo guardado
_detection_method = "MOG2"  # M√©todo de detecci√≥n por defecto
_background_suppression_enabled = True  # Estado de habilitaci√≥n de la supresi√≥n de fondo
_detection_params = {
    "var_threshold": 25,
    "detect_shadows": False
}

# Variables para detecci√≥n de movimiento en √°rea espec√≠fica
_area_mask = None
_area_points = []
_is_drawing_area = False
_area_detection_active = False

# Variables para snapshoot y procesamiento de objetos
_detected_objects = []  # Lista de objetos detectados en el √∫ltimo frame
_snapshot_mask = None   # M√°scara del objeto m√°s grande para snapshoot
_snapshot_image = None  # Imagen del objeto capturado para snapshoot
_snapshot_mode = False  # Modo para mostrar la imagen en lugar del video

# Variables para resoluci√≥n dual
_high_res_capture = None  # Captura de alta resoluci√≥n para snapshoot
_dual_resolution_mode = True  # Activar modo resoluci√≥n dual (detecci√≥n baja, snapshoot alta)
_detection_resolution = (640, 480)  # Resoluci√≥n para detecci√≥n (baja) - solo para procesamiento
_snapshot_resolution = (1280, 720)  # Resoluci√≥n para snapshoot (alta) - solo para procesamiento
_original_resolution = None  # Resoluci√≥n original de la c√°mara (para mantener FOV)

def unified_detection_pipeline(frame, params):
    """
    PIPELINE UNIFICADO Y LINEAL para detecci√≥n de objetos.
    Esta funci√≥n maneja TODO el flujo de procesamiento de forma secuencial.
    
    PASOS:
    1. Inicializar m√°scara de pol√≠gono (si no existe)
    2. Reducir resoluci√≥n para detecci√≥n
    3. Aplicar filtros en cascada
    4. Aplicar m√°scara de pol√≠gono (si habilitada)
    5. Aplicar supresi√≥n de fondo
    6. Encontrar y filtrar contornos
    7. Validar contornos contra pol√≠gono
    8. Dibujar resultados
    """
    global _area_mask, _area_points, _background_subtractor, _detected_objects
    
    cv2 = _cv2_safe()
    if cv2 is None:
        return frame
    
    import numpy as np
    
    try:
        # PASO 1: INICIALIZAR M√ÅSCARA DE POL√çGONO
        if len(_area_points) >= 3 and _area_mask is None:
            _area_mask = create_polygon_mask()
        
        # PASO 2: PREPARAR RESOLUCI√ìN Y APLICAR FILTROS
        original_height, original_width = frame.shape[:2]
        
        if _dual_resolution_mode and _detection_resolution:
            detection_width, detection_height = _detection_resolution
            detection_frame = cv2.resize(frame, (detection_width, detection_height))
        else:
            detection_frame = frame
            detection_width, detection_height = original_width, original_height
        
        # PASO 3: APLICAR FILTROS Y M√ÅSCARA
        from .filters import apply_cascade_filters_to_frame
        filtered_frame = apply_cascade_filters_to_frame(detection_frame)
        
        polygon_restriction_enabled = params.get("polygon_restriction_enabled", True)
        if polygon_restriction_enabled and _area_mask is not None:
            area_mask_resized = cv2.resize(_area_mask, (detection_width, detection_height))
            final_detection_frame = cv2.bitwise_and(filtered_frame, filtered_frame, mask=area_mask_resized)
        else:
            final_detection_frame = filtered_frame
        
        # PASO 4: APLICAR SUPRESI√ìN DE FONDO
        if _background_subtractor is None:
            _background_subtractor = _create_background_subtractor()
        
        learning_rate = params.get("learning_rate", 0.01) if _is_learning_background else 0.0
        fg_mask = _background_subtractor.apply(final_detection_frame, learningRate=learning_rate)
        
        # Debug para KNN
        if _detection_method == "KNN":
            print(f"[KNN] M√©todo: {_detection_method}, Learning rate: {learning_rate}")
            print(f"[KNN] M√°scara generada - Valores √∫nicos: {np.unique(fg_mask)}")
            print(f"[KNN] Forma de m√°scara: {fg_mask.shape}")
        
        # PASO 5: PROCESAR CONTORNOS
        contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        # Par√°metros de filtrado
        min_area = params.get("min_contour_area", 500)
        solidity_threshold = params.get("solidity_threshold", 0.7)
        margin_pixels = params.get("polygon_margin", 5)
        
        _detected_objects = []  # Limpiar lista
        scale_x = original_width / detection_width
        scale_y = original_height / detection_height
        
        for contour in contours:
            area = cv2.contourArea(contour)
            
            # Filtros b√°sicos
            if area <= min_area:
                continue
                
            hull = cv2.convexHull(contour)
            hull_area = cv2.contourArea(hull)
            solidity = float(area) / hull_area if hull_area > 0 else 0
            
            if solidity <= solidity_threshold:
                continue
            
            # Validar posici√≥n en pol√≠gono
            if polygon_restriction_enabled and _area_mask is not None:
                if not _validate_contour_inside_polygon_unified(contour, (detection_height, detection_width), margin_pixels):
                    continue
            
            # Objeto v√°lido - almacenar informaci√≥n
            x, y, w, h = cv2.boundingRect(contour)
            
            orig_x = int(x * scale_x)
            orig_y = int(y * scale_y)
            orig_w = int(w * scale_x)
            orig_h = int(h * scale_y)
            
            _detected_objects.append({
                'contour': contour,
                'area': area,
                'bbox': (orig_x, orig_y, orig_w, orig_h),
                'bbox_norm': (orig_x / original_width, orig_y / original_height, 
                             orig_w / original_width, orig_h / original_height),
                'mask': fg_mask[y:y+h, x:x+w]
            })
        
        # PASO 6: RENDERIZAR RESULTADOS
        result = _render_detection_results(frame, _detected_objects, scale_x, scale_y, 
                                         original_width, original_height)
        return result
        
    except Exception as e:
        print(f"[unified_pipeline] ‚ùå Error en pipeline: {e}")
        return frame

def _render_detection_results(frame, detected_objects, scale_x, scale_y, frame_width, frame_height):
    """Renderiza los resultados de detecci√≥n en el frame."""
    global _area_points, _area_mask, _is_learning_background, _is_drawing_area
    
    cv2 = _cv2_safe()
    if cv2 is None:
        return frame
    
    import numpy as np
    result = frame.copy()
    
    # Dibujar pol√≠gono si existe y no est√° en modo dibujo
    if len(_area_points) >= 3 and not _is_drawing_area:
        if _area_mask is not None:
            masked_frame = cv2.bitwise_and(frame, frame, mask=_area_mask)
            result = cv2.addWeighted(result, 0.3, masked_frame, 0.7, 0)
        
        # Dibujar contorno del pol√≠gono
        pixel_points = []
        for norm_x, norm_y in _area_points:
            x = int(norm_x * frame_width)
            y = int(norm_y * frame_height)
            pixel_points.append([x, y])
        cv2.polylines(result, [np.array(pixel_points, dtype=np.int32)], True, (0, 255, 0), 2)
    
    # Dibujar objetos detectados
    for obj in detected_objects:
        orig_x, orig_y, orig_w, orig_h = obj['bbox']
        
        # Suavizar contorno
        contour = obj['contour']
        epsilon = 0.02 * cv2.arcLength(contour, True)
        approx_contour = cv2.approxPolyDP(contour, epsilon, True)
        
        # Convertir contorno al frame original
        contour_orig = approx_contour.copy()
        contour_orig[:, :, 0] = (contour_orig[:, :, 0] * scale_x).astype(int)
        contour_orig[:, :, 1] = (contour_orig[:, :, 1] * scale_y).astype(int)
        
        cv2.drawContours(result, [contour_orig], -1, (0, 255, 0), 2)
        cv2.rectangle(result, (orig_x, orig_y), (orig_x + orig_w, orig_y + orig_h), (255, 0, 0), 2)
        cv2.putText(result, f"Area: {int(obj['area'])}", (orig_x, orig_y - 10), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
    
    # Indicadores de estado
    if _is_learning_background:
        cv2.putText(result, "CONFIGURANDO...", (10, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
    elif len(detected_objects) > 0:
        cv2.putText(result, "DETECCION ACTIVA", (10, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
    
    return result

# FUNCI√ìN ELIMINADA: _prepare_frame_for_detection()
# Funcionalidad integrada en unified_detection_pipeline()

def _apply_detection(frame, params):
    """Aplica detecci√≥n de objetos solo dentro del √°rea del pol√≠gono."""
    global _background_subtractor, _is_learning_background, _area_mask, _area_points, _area_detection_active, _is_drawing_area
    
    cv2 = _cv2_safe()
    if cv2 is None:
        return frame
    
    # Importar numpy
    import numpy as np
    
    try:
        # USAR EL PIPELINE UNIFICADO
        return unified_detection_pipeline(frame, params)
        
    except Exception as e:
        print(f"[detection] Error en detecci√≥n: {e}")
        return frame

# FUNCI√ìN ELIMINADA: _apply_object_detection()
# Funcionalidad integrada en unified_detection_pipeline()

# FUNCI√ìN ELIMINADA: _apply_area_detection()
# Funcionalidad integrada en unified_detection_pipeline()

def toggle_background_learning():
    """Alterna el modo de aprendizaje del fondo para detecci√≥n de objetos."""
    global _is_learning_background, _background_subtractor, _background_model_saved
    
    cv2 = _cv2_safe()
    if cv2 is None:
        return False
    
    _is_learning_background = not _is_learning_background
    
    if _is_learning_background:
        # Inicializar el subtractor de fondo con el m√©todo configurado
        _background_subtractor = _create_background_subtractor()
        print(f"[object_detection] ‚úÖ Iniciando aprendizaje del fondo (learningRate=0.01) - M√©todo: {_detection_method}")
    else:
        # Al detener el aprendizaje, marcar que hay un modelo guardado
        if _background_subtractor is not None:
            _background_model_saved = True
            print(f"[object_detection] üõë Deteniendo aprendizaje del fondo (learningRate=0.0) - Modelo guardado")
        else:
            print(f"[object_detection] üõë Deteniendo aprendizaje del fondo (learningRate=0.0)")
    
    return _is_learning_background

def get_background_learning_status():
    """Obtiene el estado actual del aprendizaje del fondo."""
    return {
        "is_learning": _is_learning_background,
        "has_model": _background_model_saved
    }

def start_background_learning():
    """Inicia el aprendizaje del fondo de forma controlada."""
    global _is_learning_background, _background_subtractor
    
    cv2 = _cv2_safe()
    if cv2 is None:
        return False
    
    if _is_learning_background:
        print(f"[object_detection] El aprendizaje ya est√° activo")
        return True
    
    # Inicializar el subtractor de fondo con el m√©todo configurado
    _background_subtractor = _create_background_subtractor()
    _is_learning_background = True
    
    print(f"[object_detection] ‚úÖ Iniciando aprendizaje autom√°tico del fondo - M√©todo: {_detection_method}")
    return True

def stop_background_learning():
    """Detiene el aprendizaje del fondo de forma controlada."""
    global _is_learning_background, _background_model_saved
    
    if not _is_learning_background:
        print(f"[object_detection] El aprendizaje no est√° activo")
        return True
    
    # Al detener el aprendizaje, marcar que hay un modelo guardado
    if _background_subtractor is not None:
        _background_model_saved = True
    
    _is_learning_background = False
    print(f"[object_detection] üõë Aprendizaje autom√°tico del fondo detenido - Modelo guardado")
    return True

def start_area_drawing():
    """Inicia el modo de dibujo de √°rea para detecci√≥n de movimiento."""
    global _is_drawing_area, _area_points
    _is_drawing_area = True
    _area_points = []
    print(f"[area_detection] Iniciando dibujo de √°rea")
    return True

def stop_area_drawing():
    """Detiene el modo de dibujo de √°rea."""
    global _is_drawing_area
    _is_drawing_area = False
    print(f"[area_detection] Deteniendo dibujo de √°rea")
    return False

def start_area_detection():
    """Activa la detecci√≥n de objetos en el √°rea (mantenido por compatibilidad)."""
    global _area_detection_active
    _area_detection_active = True
    print(f"[area_detection] ‚úÖ Activando detecci√≥n manual de objetos")
    return True

def stop_area_detection():
    """Desactiva la detecci√≥n de objetos en el √°rea (mantenido por compatibilidad)."""
    global _area_detection_active
    _area_detection_active = False
    print(f"[area_detection] Desactivando detecci√≥n manual de objetos")
    return False

def add_area_point(x: int, y: int):
    """Agrega un punto al √°rea de detecci√≥n."""
    global _area_points
    if _is_drawing_area:
        # Convertir coordenadas de p√≠xeles a normalizadas (0-1)
        frame_width, frame_height = _get_frame_dimensions()
        norm_x = x / frame_width
        norm_y = y / frame_height
        
        # Guardar coordenadas normalizadas
        _area_points.append((norm_x, norm_y))
        print(f"[area_detection] Punto agregado: ({x}, {y}) -> normalizado: ({norm_x:.3f}, {norm_y:.3f})")
        return True
    return False

def close_area():
    """Cierra el √°rea y genera la m√°scara."""
    global _area_points, _area_mask, _is_drawing_area, _area_detection_active
    
    if len(_area_points) < 3:
        print(f"[area_detection] Se necesitan al menos 3 puntos para cerrar el √°rea")
        return False
    
    # Crear la m√°scara
    _area_mask = create_polygon_mask()
    if _area_mask is not None:
        _is_drawing_area = False
        # NO activar autom√°ticamente la detecci√≥n - el usuario debe activarla manualmente
        _area_detection_active = False
        print(f"[area_detection] √Årea cerrada con {len(_area_points)} puntos (detecci√≥n inactiva)")
        return True
    else:
        print(f"[area_detection] Error creando m√°scara")
        return False

def get_area_status():
    """Obtiene el estado actual del √°rea de detecci√≥n."""
    return {
        "is_drawing": _is_drawing_area,
        "is_active": _area_detection_active,
        "points": _area_points.copy(),
        "has_mask": _area_mask is not None
    }

def _polish_contours(contours, frame_shape, params=None):
    """Aplica pulido a los contornos para mejorar su calidad."""
    cv2 = _cv2_safe()
    np = _np_safe()
    if cv2 is None or np is None:
        return contours
    
    try:
        polished_contours = []
        
        for contour in contours:
            # Suavizar contorno con spline
            smoothed_contour = _smooth_contour_spline(contour, params)
            
            # Remover puntos redundantes
            cleaned_contour = _remove_redundant_points(smoothed_contour, params)
            
            # Validar calidad del contorno
            if _validate_contour_quality(cleaned_contour, frame_shape, params):
                polished_contours.append(cleaned_contour)
        
        return polished_contours
        
    except Exception as e:
        print(f"[contour_polish] Error puliendo contornos: {e}")
        return contours

def _smooth_contour_spline(contour, params):
    """Suaviza un contorno usando interpolaci√≥n spline."""
    np = _np_safe()
    if np is None:
        return contour
    
    try:
        # Intentar importar scipy para spline
        try:
            from scipy.interpolate import splprep, splev
        except ImportError:
            return contour
        
        # Extraer puntos del contorno
        points = contour.reshape(-1, 2)
        
        if len(points) < 4:
            return contour
        
        # Preparar puntos para spline (necesita ser cerrado)
        x = points[:, 0]
        y = points[:, 1]
        
        # Cerrar el contorno si no est√° cerrado
        if not (x[0] == x[-1] and y[0] == y[-1]):
            x = np.append(x, x[0])
            y = np.append(y, y[0])
        
        # Ajustar spline
        tck, u = splprep([x, y], s=0, per=True)
        
        # Generar puntos suavizados
        new_points = splev(u, tck)
        
        # Convertir de vuelta a formato de contorno
        smoothed_points = np.column_stack(new_points).astype(np.int32)
        smoothed_contour = smoothed_points.reshape(-1, 1, 2)
        
        return smoothed_contour
        
    except Exception as e:
        print(f"[contour_polish] Error suavizando contorno: {e}")
        return contour

def _remove_redundant_points(contour, params):
    """Remueve puntos redundantes del contorno."""
    cv2 = _cv2_safe()
    np = _np_safe()
    if cv2 is None or np is None:
        return contour
    
    try:
        # Usar aproximaci√≥n de Douglas-Peucker
        epsilon = params.get("epsilon", 0.02) if params else 0.02
        arc_length = cv2.arcLength(contour, True)
        epsilon_value = epsilon * arc_length
        
        approx_contour = cv2.approxPolyDP(contour, epsilon_value, True)
        
        return approx_contour
        
    except Exception as e:
        print(f"[contour_polish] Error removiendo puntos redundantes: {e}")
        return contour

def _validate_contour_quality(contour, frame_shape, params):
    """Valida la calidad de un contorno."""
    cv2 = _cv2_safe()
    if cv2 is None:
        return True
    
    try:
        # Calcular √°rea
        area = cv2.contourArea(contour)
        
        # √Årea m√≠nima
        min_area = params.get("min_area", 100) if params else 100
        if area < min_area:
            return False
        
        # Calcular per√≠metro
        perimeter = cv2.arcLength(contour, True)
        
        # Evitar contornos muy peque√±os o muy grandes
        frame_area = frame_shape[0] * frame_shape[1]
        if area > frame_area * 0.8:  # No m√°s del 80% del frame
            return False
        
        # Verificar que el contorno tenga suficientes puntos
        if len(contour) < 3:
            return False
        
        return True
        
    except Exception as e:
        print(f"[contour_polish] Error validando contorno: {e}")
        return False

def normalize_coordinates(x, y, width, height):
    """
    Convierte coordenadas de p√≠xeles a coordenadas normalizadas (0-1).
    
    Args:
        x, y: Coordenadas en p√≠xeles
        width, height: Dimensiones del frame
    
    Returns:
        tuple: (norm_x, norm_y) coordenadas normalizadas
    """
    return (x / width, y / height)

def denormalize_coordinates(norm_x, norm_y, width, height):
    """
    Convierte coordenadas normalizadas (0-1) a coordenadas de p√≠xeles.
    
    Args:
        norm_x, norm_y: Coordenadas normalizadas (0-1)
        width, height: Dimensiones del frame
    
    Returns:
        tuple: (x, y) coordenadas en p√≠xeles
    """
    return (int(norm_x * width), int(norm_y * height))

# FUNCI√ìN ELIMINADA: _validate_contour_inside_polygon()
# Reemplazada por _validate_contour_inside_polygon_unified()

def _validate_contour_inside_polygon_unified(contour, frame_shape, margin_pixels=5):
    """
    Versi√≥n unificada de validaci√≥n de contorno dentro del pol√≠gono.
    """
    global _area_mask, _area_points
    
    cv2 = _cv2_safe()
    if cv2 is None:
        return True
    
    try:
        if _area_mask is None or len(_area_points) < 3:
            return True
        
        frame_height, frame_width = frame_shape
        x, y, w, h = cv2.boundingRect(contour)
        
        # Verificar margen del frame
        if x < margin_pixels or y < margin_pixels or x + w > frame_width - margin_pixels or y + h > frame_height - margin_pixels:
            return False
        
        # Redimensionar m√°scara al frame de detecci√≥n
        detection_mask = cv2.resize(_area_mask, (frame_width, frame_height))
        
        # Crear m√°scara con margen
        margin_mask = detection_mask.copy()
        if margin_pixels > 0:
            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (margin_pixels * 2 + 1, margin_pixels * 2 + 1))
            margin_mask = cv2.erode(detection_mask, kernel, iterations=1)
        
        # Verificar todos los puntos del contorno
        for point in contour:
            px, py = point[0]
            if px >= 0 and py >= 0 and px < frame_width and py < frame_height:
                if margin_mask[py, px] == 0:
                    return False
        
        return True
        
    except Exception as e:
        print(f"[polygon_validation] Error: {e}")
        return False

def save_polygon_to_config():
    """Guarda el pol√≠gono actual en la configuraci√≥n."""
    global _area_points
    
    try:
        from .utils import load_config, save_config
        
        # Cargar configuraci√≥n actual
        config = load_config()
        
        # Guardar puntos del pol√≠gono
        config.setdefault("detection", {})["area_points"] = _area_points
        
        # Guardar configuraci√≥n
        save_config(config)
        
        print(f"[area] Pol√≠gono guardado en configuraci√≥n: {len(_area_points)} puntos")
        return True
        
    except Exception as e:
        print(f"[area] Error guardando pol√≠gono: {e}")
        return False

def load_polygon_from_config():
    """Carga el pol√≠gono desde la configuraci√≥n."""
    global _area_points, _area_mask
    
    try:
        from .utils import load_config
        
        # Cargar configuraci√≥n
        config = load_config()
        
        # Obtener puntos del pol√≠gono
        area_points = config.get("detection", {}).get("area_points", [])
        
        if len(area_points) >= 3:
            _area_points = area_points
            _area_mask = None  # Forzar recreaci√≥n de m√°scara
            print(f"[area] Pol√≠gono cargado desde configuraci√≥n: {len(_area_points)} puntos")
            return True
        else:
            print("[area] No hay pol√≠gono v√°lido en configuraci√≥n")
            return False
        
    except Exception as e:
        print(f"[area] Error cargando pol√≠gono: {e}")
        return False

def take_snapshot_with_mask():
    """
    Toma un snapshot del objeto m√°s grande detectado usando coordenadas normalizadas.
    Usa el stream original de alta resoluci√≥n para m√°xima calidad.
    """
    global _snapshot_mode, _snapshot_image, _snapshot_mask, _detected_objects
    
    try:
        from .camera_manager import get_jpeg
        
        # Obtener frame actual de alta resoluci√≥n
        jpeg_data = get_jpeg()
        if jpeg_data is None:
            return False, "No hay imagen disponible"
        
        # Decodificar imagen
        import cv2
        import numpy as np
        
        # Convertir bytes a array numpy
        nparr = np.frombuffer(jpeg_data, np.uint8)
        frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        
        if frame is None:
            return False, "Error decodificando imagen"
        
        # Si hay objetos detectados, tomar snapshot del m√°s grande
        if _detected_objects:
            # Encontrar el objeto con mayor √°rea
            largest_object = max(_detected_objects, key=lambda obj: obj['area'])
            
            # Obtener coordenadas normalizadas del objeto
            norm_x, norm_y, norm_w, norm_h = largest_object['bbox_norm']
            
            # Obtener dimensiones del frame original
            frame_height, frame_width = frame.shape[:2]
            
            # Convertir coordenadas normalizadas a p√≠xeles en el frame original
            x = int(norm_x * frame_width)
            y = int(norm_y * frame_height)
            w = int(norm_w * frame_width)
            h = int(norm_h * frame_height)
            
            # Asegurar que las coordenadas est√©n dentro del frame
            x = max(0, min(x, frame_width - 1))
            y = max(0, min(y, frame_height - 1))
            w = min(w, frame_width - x)
            h = min(h, frame_height - y)
            
            # Extraer el objeto del frame original (alta resoluci√≥n)
            object_snapshot = frame[y:y+h, x:x+w]
            
            # Si hay m√°scara de pol√≠gono, aplicarla al snapshot
            if len(_area_points) >= 3:
                mask = create_polygon_mask()
                if mask is not None:
                    # Redimensionar m√°scara al tama√±o del objeto
                    object_mask = mask[y:y+h, x:x+w]
                    object_snapshot = cv2.bitwise_and(object_snapshot, object_snapshot, mask=object_mask)
            
            _snapshot_image = object_snapshot
            _snapshot_mode = True
            print(f"[snapshot] ‚úÖ Snapshot de objeto tomado: {w}x{h} p√≠xeles (√°rea: {largest_object['area']})")
            return True, f"Snapshot tomado exitosamente - Objeto: {w}x{h} p√≠xeles"
        
        # Si no hay objetos detectados, tomar snapshot completo
        _snapshot_image = frame
        _snapshot_mode = True
        print("[snapshot] Snapshot completo tomado (sin objetos detectados)")
        return True, "Snapshot completo tomado exitosamente"
        
    except Exception as e:
        print(f"[snapshot] Error tomando snapshot: {e}")
        return False, f"Error: {str(e)}"

def clear_snapshot_mode():
    """Limpia el modo snapshot."""
    global _snapshot_mode, _snapshot_image, _snapshot_mask
    
    _snapshot_mode = False
    _snapshot_image = None
    _snapshot_mask = None
    print("[snapshot] Modo snapshot limpiado")

def get_snapshot_status():
    """Obtiene el estado del snapshot."""
    global _snapshot_mode, _snapshot_image
    
    return {
        "mode": _snapshot_mode,
        "has_image": _snapshot_image is not None
    }

def set_detection_method(method: str, params: dict = None, enabled: bool = True):
    """Configura el m√©todo de detecci√≥n de objetos."""
    global _detection_method, _detection_params, _background_subtractor, _background_suppression_enabled
    
    cv2 = _cv2_safe()
    if cv2 is None:
        return False, "OpenCV no disponible"
    
    valid_methods = ["MOG2", "KNN"]
    if method not in valid_methods:
        return False, f"M√©todo no v√°lido. Opciones: {', '.join(valid_methods)}"
    
    try:
        # Actualizar m√©todo, par√°metros y estado de habilitaci√≥n
        _detection_method = method
        _background_suppression_enabled = enabled
        if params:
            _detection_params.update(params)
        
        # Reinicializar el subtractor con el nuevo m√©todo solo si est√° habilitado
        if enabled:
            _background_subtractor = _create_background_subtractor()
        else:
            _background_subtractor = None
        
        status = "habilitado" if enabled else "deshabilitado"
        print(f"[detection] M√©todo de detecci√≥n {method} {status}")
        return True, f"M√©todo {method} {status}"
        
    except Exception as e:
        print(f"[detection] Error configurando m√©todo de detecci√≥n: {e}")
        return False, f"Error: {str(e)}"

def get_detection_method():
    """Obtiene el m√©todo de detecci√≥n actual y sus par√°metros."""
    global _detection_method, _detection_params, _background_suppression_enabled
    
    return {
        "method": _detection_method,
        "enabled": _background_suppression_enabled,
        "params": _detection_params.copy()
    }

def _create_background_subtractor():
    """Crea un subtractor de fondo seg√∫n el m√©todo y configuraci√≥n actual."""
    global _detection_method, _detection_params, _algorithm_configs
    
    cv2 = _cv2_safe()
    if cv2 is None:
        return None
    
    try:
        # Usar configuraci√≥n espec√≠fica del algoritmo o fallback a par√°metros globales
        config = _algorithm_configs.get(_detection_method, {})
        
        if _detection_method == "MOG2":
            return cv2.createBackgroundSubtractorMOG2(
                history=config.get("history", 500),
                varThreshold=config.get("varThreshold", _detection_params.get("var_threshold", 25)),
                detectShadows=config.get("detectShadows", _detection_params.get("detect_shadows", False))
            )
        elif _detection_method == "KNN":
            knn_config = {
                "history": config.get("history", 500),
                "dist2Threshold": config.get("dist2Threshold", 1000.0),
                "detectShadows": config.get("detectShadows", False)
            }
            print(f"[detection] Creando KNN con configuraci√≥n: {knn_config}")
            return cv2.createBackgroundSubtractorKNN(**knn_config)
        else:
            # Fallback a MOG2
            return cv2.createBackgroundSubtractorMOG2(
                history=500,
                varThreshold=_detection_params.get("var_threshold", 25),
                detectShadows=_detection_params.get("detect_shadows", False)
            )
            
    except Exception as e:
        print(f"[detection] Error creando subtractor de fondo: {e}")
        return None

# Configuraciones espec√≠ficas por algoritmo
_algorithm_configs = {
    "MOG2": {
        "history": 500,
        "varThreshold": 16,
        "detectShadows": True,
        "shadowValue": 127
    },

    "KNN": {
        "history": 500,
        "dist2Threshold": 1000,  # Umbral m√°s alto para detectar m√°s objetos
        "detectShadows": False,  # Deshabilitar sombras para KNN
        "shadowValue": 127
    }
}

# Configuraci√≥n de aprendizaje del modelo
_learning_config = {
    "learning_rate": 0.01,
    "epochs": 100,
    "batch_size": 16,
    "validation_split": 0.2,
    "early_stopping": True,
    "data_augmentation": True,
    "normalization": "standard"
}

def get_algorithm_config(algorithm: str):
    """Obtiene la configuraci√≥n espec√≠fica de un algoritmo."""
    global _algorithm_configs
    
    if algorithm not in _algorithm_configs:
        return {}
    
    return _algorithm_configs[algorithm].copy()

def set_algorithm_config(algorithm: str, config: dict):
    """Configura los par√°metros espec√≠ficos de un algoritmo."""
    global _algorithm_configs, _background_subtractor, _detection_method
    
    cv2 = _cv2_safe()
    if cv2 is None:
        return False, "OpenCV no disponible"
    
    if algorithm not in _algorithm_configs:
        return False, f"Algoritmo no v√°lido: {algorithm}"
    
    try:
        # Actualizar configuraci√≥n
        _algorithm_configs[algorithm].update(config)
        
        # Si es el algoritmo actual, reinicializar el subtractor
        if algorithm == _detection_method:
            _background_subtractor = _create_background_subtractor()
        
        print(f"[detection] Configuraci√≥n de {algorithm} actualizada")
        return True, f"Configuraci√≥n de {algorithm} guardada"
        
    except Exception as e:
        print(f"[detection] Error configurando {algorithm}: {e}")
        return False, f"Error: {str(e)}"

def get_learning_config():
    """Obtiene la configuraci√≥n de aprendizaje del modelo."""
    global _learning_config
    return _learning_config.copy()

def set_learning_config(config: dict):
    """Configura los par√°metros de aprendizaje del modelo."""
    global _learning_config
    
    try:
        # Actualizar configuraci√≥n
        _learning_config.update(config)
        
        print(f"[detection] Configuraci√≥n de aprendizaje actualizada")
        return True, "Configuraci√≥n de aprendizaje guardada"
        
    except Exception as e:
        print(f"[detection] Error configurando aprendizaje: {e}")
        return False, f"Error: {str(e)}"

def debug_knn_detection():
    """Funci√≥n de diagn√≥stico para KNN."""
    global _detection_method, _background_subtractor, _algorithm_configs
    
    print(f"[KNN_DEBUG] M√©todo actual: {_detection_method}")
    print(f"[KNN_DEBUG] Configuraci√≥n KNN: {_algorithm_configs.get('KNN', {})}")
    print(f"[KNN_DEBUG] Subtractors activos: {_background_subtractor is not None}")
    
    if _detection_method == "KNN":
        print(f"[KNN_DEBUG] ‚úÖ KNN est√° configurado como m√©todo activo")
        if _background_subtractor is not None:
            print(f"[KNN_DEBUG] ‚úÖ Subtractors KNN creado correctamente")
        else:
            print(f"[KNN_DEBUG] ‚ùå Subtractors KNN no est√° creado")
    else:
        print(f"[KNN_DEBUG] ‚ö†Ô∏è KNN no es el m√©todo activo (actual: {_detection_method})")
    
    return {
        "method": _detection_method,
        "knn_config": _algorithm_configs.get('KNN', {}),
        "subtractor_active": _background_subtractor is not None
    }

# FUNCI√ìN ELIMINADA: _create_background_subtractor_with_config()
# Funcionalidad consolidada en _create_background_subtractor()
